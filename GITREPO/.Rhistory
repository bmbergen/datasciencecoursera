as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
##dtm$Mday=All$Mday
##dtm$NewsDesk=All$NewsDesk
dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
##dtm$Mday=All$Mday
##dtm$NewsDesk=All$NewsDesk
dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
##dtm$Mday=All$Mday
##dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
##dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
##dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
##numFolds=trainControl(method="cv",number=20)
##cpGrid=expand.grid(.cp=seq(0.01,1,0.01))
##train(as.factor(Popular) ~ .,method="rpart",data=TrainTrain,trControl=numFolds,tuneGrid=cpGrid)
CPModel=rpart(as.factor(Popular)~.,data=TrainTrain,method="class",cp=0.0001)
##TrainTrain Predections and AUC
PredictCP=predict(CPModel,type="prob")[,2]
ROCRpredCPTrain=prediction(PredictCP,TrainTrain$Popular)
as.numeric(performance(ROCRpredCPTrain,"auc")@y.values)
##TrainTest Predections and AUC
PredictCP=predict(CPModel,newdata=TrainTest,type="prob")[,2]
ROCRpredCPTrainTest=prediction(PredictCP,TrainTest$Popular)
as.numeric(performance(ROCRpredCPTrainTest,"auc")@y.values)
dtm=cbind(dtmHeadline,dtmAbstract,row.names=NULL)
##dtm=dtmAbstract
#str(dtm)
##dtm$WordCount=NewsTrain$WordCount
dtm$LogWordCount=All$LogWordCount
dtm$Hour=All$Hour
dtm$Wday=All$Wday
dtm$Mday=All$Mday
dtm$NewsDesk=All$NewsDesk
##dtm$SectionName=All$SectionName
dtm$SubsectionName=All$SubsectionName
##str(dtm)
##Split train and test data back to the original train and test
Train=head(dtm,nrow(NewsTrain))
Test=tail(dtm,nrow(NewsTest))
##Add Popular back to Train
Train$Popular=NewsTrain$Popular
##Split Train to so I can do AUC preds on a subset
split=sample.split(Train$Popular,SplitRatio=0.75)
TrainTrain = subset(Train,split==TRUE)
TrainTest=subset(Train,split==FALSE)
##Model
library(caret)
library(e1071)
##numFolds=trainControl(method="cv",number=10)
##cpGrid=expand.grid(.cp=seq(0.01,0.5,0.01))
numFolds=trainControl(method="cv",number=20)
cpGrid=expand.grid(.cp=seq(0.0001,1,0.0001))
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
str(NewsTrain)
##Base created 4/22/15
##Loads files
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
##Combines original files after removing Popular from Train
Train_No_Pop = NewsTrain[c(-9)]
All = rbind(Train_No_Pop, NewsTest)
##Extract date day info
All$PubDate = strptime(All$PubDate, "%Y-%m-%d %H:%M:%S")
All$Hour = All$PubDate$hour
All$Wday = All$PubDate$wday
All$Mday = All$PubDate$mday
All$PubDate = NULL
##Log Word Count
All$LogWordCount=log(1+All$WordCount)
##Turn NewsDesk, SectionName, and Subsection Name into factors
All$NewsDesk=as.factor(All$NewsDesk)
All$SectionName=as.factor(All$SectionName)
All$SubsectionName=as.factor(All$SubsectionName)
##Fix Levels
levels(All$NewsDesk) = levels(All$NewsDesk)
levels(All$SectionName) = levels(All$SectionName)
levels(All$SubsectionName) = levels(All$SubsectionName)
##sparse percentage
##the higher the percentage the more terms
SP=0.99
##corpus of Headline
corpusHeadline = Corpus(VectorSource(All$Headline))
corpusHeadline = tm_map(corpusHeadline, tolower)
corpusHeadline = tm_map(corpusHeadline, PlainTextDocument)
corpusHeadline = tm_map(corpusHeadline, removePunctuation)
corpusHeadline = tm_map(corpusHeadline, removeWords, stopwords("english"))
corpusHeadline = tm_map(corpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(corpusHeadline)
sparse = removeSparseTerms(dtmHeadline, SP)
dtmHeadline = as.data.frame(as.matrix(sparse))
str(dtmHeadline)
SP=0.999
##corpus of Headline
corpusHeadline = Corpus(VectorSource(All$Headline))
corpusHeadline = tm_map(corpusHeadline, tolower)
corpusHeadline = tm_map(corpusHeadline, PlainTextDocument)
corpusHeadline = tm_map(corpusHeadline, removePunctuation)
corpusHeadline = tm_map(corpusHeadline, removeWords, stopwords("english"))
corpusHeadline = tm_map(corpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(corpusHeadline)
sparse = removeSparseTerms(dtmHeadline, SP)
dtmHeadline = as.data.frame(as.matrix(sparse))
str(dtmHeadline)
##Loads files
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
##
NewsTrainPop=subset(NewsTrain,Popular=1)
str(NewsTrainPop)
NewsTrain = read.csv("NYTimesBlogTrain.csv", stringsAsFactors=FALSE)
NewsTest = read.csv("NYTimesBlogTest.csv", stringsAsFactors=FALSE)
##
NewsTrainPop=subset(NewsTrain,Popular==1)
str(NewsTrainPop)
NewsTrainPop=subset(NewsTrain,Popular==1)
str(NewsTrain)
str(NewsTrainPop)
SP=0.99999
##corpus of Headline
corpusHeadline = Corpus(VectorSource(NewsTrainPop$Headline))
corpusHeadline = tm_map(corpusHeadline, tolower)
corpusHeadline = tm_map(corpusHeadline, PlainTextDocument)
corpusHeadline = tm_map(corpusHeadline, removePunctuation)
corpusHeadline = tm_map(corpusHeadline, removeWords, stopwords("english"))
corpusHeadline = tm_map(corpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(corpusHeadline)
sparse = removeSparseTerms(dtmHeadline, SP)
dtmHeadline = as.data.frame(as.matrix(sparse))
str(dtmHeadline)
findFreqTerms(frequencies,lowfreq=20)
findFreqTerms(frequencies,lowfreq=30)
findFreqTerms(frequencies,lowfreq=40)
findFreqTerms(dtmHeadline,lowfreq=40)
corpusHeadline = Corpus(VectorSource(NewsTrainPop$Headline))
corpusHeadline = tm_map(corpusHeadline, tolower)
corpusHeadline = tm_map(corpusHeadline, PlainTextDocument)
corpusHeadline = tm_map(corpusHeadline, removePunctuation)
corpusHeadline = tm_map(corpusHeadline, removeWords, stopwords("english"))
corpusHeadline = tm_map(corpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(corpusHeadline)
sparse = removeSparseTerms(dtmHeadline, SP)
HeadlineDF = as.data.frame(as.matrix(sparse))
str(dtmHeadline)
findFreqTerms(dtmHeadline,lowfreq=40)
findFreqTerms(dtmHeadline,lowfreq=10)
findFreqTerms(dtmHeadline,lowfreq=5)
corpusHeadline = Corpus(VectorSource(NewsTrainPop$Headline))
corpusHeadline = tm_map(corpusHeadline, tolower)
corpusHeadline = tm_map(corpusHeadline, PlainTextDocument)
corpusHeadline = tm_map(corpusHeadline, removePunctuation)
corpusHeadline = tm_map(corpusHeadline, removeWords, stopwords("english"))
corpusHeadline = tm_map(corpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(corpusHeadline)
##sparse = removeSparseTerms(dtmHeadline, SP)
HeadlineDF = as.data.frame(as.matrix(sparse))
str(dtmHeadline)
findFreqTerms(dtmHeadline,lowfreq=5)
corpusHeadline = Corpus(VectorSource(NewsTrainPop$Headline))
corpusHeadline = tm_map(corpusHeadline, tolower)
corpusHeadline = tm_map(corpusHeadline, PlainTextDocument)
corpusHeadline = tm_map(corpusHeadline, removePunctuation)
corpusHeadline = tm_map(corpusHeadline, removeWords, stopwords("english"))
##corpusHeadline = tm_map(corpusHeadline, stemDocument)
dtmHeadline = DocumentTermMatrix(corpusHeadline)
##sparse = removeSparseTerms(dtmHeadline, SP)
HeadlineDF = as.data.frame(as.matrix(sparse))
str(dtmHeadline)
findFreqTerms(dtmHeadline,lowfreq=5)
findFreqTerms(dtmHeadline,highfreq=5)
findFreqTerms(dtmHeadline,highfreq=25)
findFreqTerms(dtmHeadline,lowfreq=25)
corpusSnippet = Corpus(VectorSource(NewsTrainPop$Snippet))
corpusSnippet = tm_map(corpusSnippet, tolower)
corpusSnippet = tm_map(corpusSnippet, PlainTextDocument)
corpusSnippet = tm_map(corpusSnippet, removePunctuation)
corpusSnippet = tm_map(corpusSnippet, removeWords, stopwords("english"))
##corpusSnippet = tm_map(corpusSnippet, stemDocument)
dtmSnippet = DocumentTermMatrix(corpusSnippet)
##sparse = removeSparseTerms(dtmSnippet, SP)
SnippetDF = as.data.frame(as.matrix(sparse))
findFreqTerms(dtmSnippet,lowfreq=25)
findFreqTerms(dtmSnippet,highfreq=25)
install.packages("KernSmooth")
library(KernSmooth)
setwd("C:/Users/bbergen022/Dropbox/JHDS/01_DSTBOX/GITREPO")
clr
clear
## This is a markdown file
